from pyspark.sql import SparkSession
import sys
import os

def verify_spark_s3_public():
    print("üöÄ Iniciando verificaci√≥n de Spark + S3 (Bucket P√∫blico)...")
    
    # Ya no necesitamos configurar JARs manualmente ni diagn√≥sticos complejos
    # porque PYSPARK_SUBMIT_ARGS en el Dockerfile se encarga de todo.
    
    try:
        spark = (SparkSession.builder
            .appName("VerifyS3Public")
            # Configuraci√≥n cr√≠tica para S3A
            .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
            # Proveedor de credenciales an√≥nimo para buckets p√∫blicos
            .config("spark.hadoop.fs.s3a.aws.credentials.provider", "org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider")
            .config("spark.hadoop.fs.s3a.endpoint", "s3.amazonaws.com")
            .getOrCreate())
        
        print(f"‚úÖ Spark Session creada. Versi√≥n: {spark.version}")
        
        # Prueba de lectura de un archivo p√∫blico
        public_s3_path = "s3a://nyc-tlc/trip data/yellow_tripdata_2023-01.parquet"
        
        print(f"üìÇ Intentando leer archivo p√∫blico: {public_s3_path}")
        
        # Leemos solo el esquema
        df = spark.read.parquet(public_s3_path)
        
        print("‚úÖ Lectura exitosa!")
        print("üìã Esquema detectado:")
        df.printSchema()
        
        print("\nüéâ VERIFICACI√ìN COMPLETADA CON √âXITO: Tu entorno est√° listo y configurado autom√°ticamente.")
        
    except Exception as e:
        print("\n‚ùå ERROR CR√çTICO DURANTE LA VERIFICACI√ìN:")
        print(str(e))
        sys.exit(1)
    finally:
        if 'spark' in locals():
            spark.stop()

if __name__ == "__main__":
    verify_spark_s3_public()
