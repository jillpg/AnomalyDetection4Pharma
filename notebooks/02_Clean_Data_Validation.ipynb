{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# Phase 2 Validation: Clean Data & Gold Layer ðŸ§ª\n",
                "\n",
                "**Goal**: Prove that the ETL Pipeline (Silver -> Gold) worked correctly.\n",
                "**Checklist**:\n",
                "1.  **Row Counts**: Do Train + Val + Test roughly match Silver?\n",
                "2.  **Scaling Check**: Is Train Mean $\\approx 0$ and Std $\\approx 1$? (Z-Score definition).\n",
                "3.  **Leakage Check**: Are Test stats different from exact 0/1? (They should be!).\n",
                "4.  **Golden Filter Effect**: Confirm filtered Train set count."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "sys.path.append(os.path.abspath('../src'))\n",
                "\n",
                "from config import get_spark_session, get_data_path\n",
                "from pyspark.ml.stat import Summarizer\n",
                "from pyspark.sql import functions as F\n",
                "\n",
                "spark = get_spark_session(\"Validation_Gold\")\n",
                "gold_path = get_data_path(\"gold\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_train = spark.read.parquet(f\"{gold_path}/Train\")\n",
                "df_val = spark.read.parquet(f\"{gold_path}/Val\")\n",
                "df_test = spark.read.parquet(f\"{gold_path}/Test\")\n",
                "\n",
                "print(f\"âœ… Loaded Train: {df_train.count()} rows\")\n",
                "print(f\"âœ… Loaded Val: {df_val.count()} rows\")\n",
                "print(f\"âœ… Loaded Test: {df_test.count()} rows\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "stats_check",
            "metadata": {},
            "source": [
                "## 2. Statistical Validation (Scaling & Leakage)\n",
                "We calculate Mean and StdDev of the `features_scaled` column (Vector).\n",
                "*   **Expectation (Train)**: Mean $\\approx 0.0$, Std $\\approx 1.0$.\n",
                "*   **Expectation (Test)**: Close to 0/1, but NOT exactly (since Scaler was fit on Train)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "check_stats",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_vector_stats(df, name):\n",
                "    # Summarizer metrics for Vector column\n",
                "    metrics = df.select(Summarizer.metrics(\"mean\", \"std\").summary(F.col(\"features_scaled\")).alias(\"metrics\")).collect()[0][\"metrics\"]\n",
                "    \n",
                "    print(f\"\\nðŸ“Š Stats for {name}:\")\n",
                "    print(f"   Mean: {metrics.mean
                }")\n",
                "    print(f"   Std: {metrics.std
                }")\n",
                "    return metrics.mean, metrics.std\n",
                "\n",
                "mean_train, std_train = get_vector_stats(df_train, \"TRAIN (Golden)\")\n",
                "mean_test, std_test = get_vector_stats(df_test, \"TEST (Raw-ish)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "visual_inspect",
            "metadata": {},
            "source": [
                "## 3. Visual Inspection\n",
                "Let's check the first 5 rows to ensure `features_scaled` looks like a DenseVector."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "head",
            "metadata": {},
            "outputs": [],
            "source": [
                "df_train.select(\"timestamp\", \"campaign\", \"features_scaled\").show(5, truncate=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0rc1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}