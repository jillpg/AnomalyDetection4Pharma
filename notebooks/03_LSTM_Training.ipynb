{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: LSTM Autoencoder Training (Kaggle Self-Contained)\n",
    "\n",
    "**Objective**: Train the 64-32-64 LSTM Autoencoder on the Physics-Enriched Tensor.\n",
    "**Refinements**: \n",
    "*   Latent Non-linearity (`LeakyReLU`)\n",
    "*   Gradient Clipping (for Linear Output stability)\n",
    "*   MAE Loss (L1)\n",
    "*   **OOM Fix**: Lazy Loading & Validation Batching\n",
    "\n",
    "**Inputs**: \n",
    "*   `train.parquet` (Upload to Kaggle Dataset)\n",
    "*   `val.parquet` (Upload to Kaggle Dataset)\n",
    "\n",
    "**Outputs**:\n",
    "*   `lstm_ae_champion.pth`\n",
    "*   Loss Curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# --- Auto-Detection: Local vs Kaggle ---\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "try:\n",
    "    from src import config\n",
    "    IS_LOCAL_ENV = True\n",
    "    print(\"\u2705 Environment Detected: LOCAL (Project Structure Found)\")\n",
    "    RESULTS_DIR = \"results/lstm\"\n",
    "    DATA_DIR = getattr(config, \"BUCKET_GOLD\", \"gold\") # Or handle S3 path logic here\n",
    "    if DATA_DIR.startswith(\"s3://\"):\n",
    "        # Simplified for now, assuming local execution uses MinIO or local/gold\n",
    "        # Unless using pandas storage_options, we might fallback to local path if s3 lookup fails\n",
    "        pass\n",
    "except ImportError:\n",
    "    IS_LOCAL_ENV = False\n",
    "    print(\"\ud83c\udf0d Environment Detected: KAGGLE (Standalone Kernel)\")\n",
    "    RESULTS_DIR = \"/kaggle/working\"\n",
    "    DATA_DIR = \"/kaggle/input/anomalydetection4pharma-gold-tensor\"\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "print(f\"Using Results Dir: {RESULTS_DIR}\")\n",
    "\n",
    "# Config\n",
    "WINDOW_SIZE = 60  # 10 minutes\n",
    "STRIDE = 5        # Overlap\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "LATENT_DIM = 3\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "# Features Expected in Parquet\n",
    "TENSOR_FEATURES = [\n",
    "    \"dynamic_tensile_strength\",\n",
    "    \"ejection\",\n",
    "    \"tbl_speed\",\n",
    "    \"cyl_main\",\n",
    "    \"tbl_fill\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Helper Functions (Embedded)\n",
    "We paste the source code here to avoid uploading `src` folders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "# From src/data/window_loader.py\n",
    "def create_windows(df, window_size=60, stride=5, feature_cols=None):\n",
    "    \"\"\"\n",
    "    Creates sequences of length `window_size` from a DataFrame.\n",
    "    \"\"\"\n",
    "    if feature_cols is None:\n",
    "        raise ValueError(\"Must provide feature_cols list\")\n",
    "        \n",
    "    X = []\n",
    "    \n",
    "    # If 'batch' column exists, we must not window across batch boundaries.\n",
    "    if 'batch' in df.columns:\n",
    "        grouped = df.groupby('batch')\n",
    "        for batch_id, group in grouped:\n",
    "            group = group.sort_values('timestamp')\n",
    "            data = group[feature_cols].values\n",
    "            num_samples = len(data)\n",
    "            if num_samples < window_size:\n",
    "                continue\n",
    "            for i in range(0, num_samples - window_size + 1, stride):\n",
    "                window = data[i : i + window_size]\n",
    "                X.append(window)\n",
    "    else:\n",
    "        data = df[feature_cols].values\n",
    "        num_samples = len(data)\n",
    "        for i in range(0, num_samples - window_size + 1, stride):\n",
    "            window = data[i : i + window_size]\n",
    "            X.append(window)\n",
    "            \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "# From src/models/lstm_ae.py\n",
    "class LSTMAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Autoencoder for Anomaly Detection in Time Series (PyTorch Version).\n",
    "    Architecture:\n",
    "        Input(Window) -> Encoder(LSTM) -> Latent(Vector) -> Decoder(LSTM) -> Output(Window)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size, n_features, latency_dim=3, hidden_dim=64, num_layers=1, dropout=0.2):\n",
    "        super(LSTMAutoencoder, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.n_features = n_features\n",
    "        self.latency_dim = latency_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=n_features, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        \n",
    "        # Latent compression\n",
    "        self.to_latent = nn.Linear(hidden_dim, latency_dim)\n",
    "        self.from_latent = nn.Linear(latency_dim, hidden_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_dim, n_features)\n",
    "        \n",
    "        # Initialize Weights\n",
    "        self._init_weights()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Xavier Initialization for better convergence.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_normal_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        _, (hidden_n, _) = self.encoder(x)\n",
    "        last_hidden = hidden_n[-1]\n",
    "        last_hidden = self.dropout_layer(last_hidden) # Apply Dropout\n",
    "        \n",
    "        # Latent\n",
    "        latent = self.to_latent(last_hidden)\n",
    "        latent = nn.functional.leaky_relu(latent) # Non-linearity for complex patterns\n",
    "        \n",
    "        # Decoder Prep\n",
    "        hidden_restored = self.from_latent(latent)\n",
    "        # Repeat for each time step\n",
    "        repeated_hidden = hidden_restored.unsqueeze(1).repeat(1, self.window_size, 1)\n",
    "        \n",
    "        # Decoder\n",
    "        dec_out, _ = self.decoder(repeated_hidden)\n",
    "        \n",
    "        # Reconstruction\n",
    "        reconstructed = self.output_layer(dec_out)\n",
    "        return reconstructed, latent # Return latent for visualization\n",
    "\n",
    "    def save_checkpoint(self, path, epoch, optimizer, loss):\n",
    "        \"\"\"Saves full checkpoint with metadata.\"\"\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            'config': {\n",
    "                'window_size': self.window_size,\n",
    "                'n_features': self.n_features, \n",
    "                'hidden_dim': self.hidden_dim,\n",
    "                'latent_dim': self.latency_dim\n",
    "            }\n",
    "        }, path)\n",
    "        print(f\"  \ud83d\udcbe Checkpoint saved: {path}\")\n",
    "\n",
    "    def train_model(self, X_train, X_val, epochs=50, batch_size=64, lr=1e-3, \n",
    "                    patience=15, scheduler_patience=3, scheduler_factor=0.5, \n",
    "                    save_path=\"models/lstm_ae_champion.pth\", noise_factor=0.0):\n",
    "        \"\"\"\n",
    "        Trains the model with Limit-aware Learning Rate Scheduler and Early Stopping.\n",
    "        Uses Lazy Loading and Validation Batching to prevent OOM.\n",
    "        \"\"\"\n",
    "        # Convert to Tensor but KEEP ON CPU initially\n",
    "        train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "        val_tensor = torch.from_numpy(X_val.astype(np.float32))\n",
    "        \n",
    "        train_loader = DataLoader(TensorDataset(train_tensor, train_tensor), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(val_tensor, val_tensor), batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        criterion = nn.L1Loss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=scheduler_factor, patience=scheduler_patience\n",
    "        )\n",
    "        \n",
    "        best_loss = float('inf')\n",
    "        counter = 0\n",
    "        history = {'train_loss': [], 'val_loss': []}\n",
    "        \n",
    "        print(f\"\ud83d\ude80 Device: {self.device}\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            for batch_x, target_x in train_loader:\n",
    "                # Move to GPU Just-In-Time\n",
    "                batch_x = batch_x.to(self.device)\n",
    "                target_x = target_x.to(self.device)\n",
    "\n",
    "                # Apply Denoising Noise (if enabled)\n",
    "                if noise_factor > 0:\n",
    "                    noise = torch.randn_like(batch_x) * noise_factor\n",
    "                    batch_x = batch_x + noise\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output, _ = self(batch_x)\n",
    "                loss = criterion(output, target_x)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "            \n",
    "            # Validation (Batched)\n",
    "            self.eval()\n",
    "            val_loss_accum = 0\n",
    "            with torch.no_grad():\n",
    "                for val_batch, _ in val_loader:\n",
    "                   val_batch = val_batch.to(self.device)\n",
    "                   val_out, _ = self(val_batch)\n",
    "                   batch_loss = criterion(val_out, val_batch).item()\n",
    "                   val_loss_accum += batch_loss\n",
    "            \n",
    "            avg_val_loss = val_loss_accum / len(val_loader)\n",
    "            \n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}\")\n",
    "            \n",
    "            # Update Scheduler\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "            # Checkpoint\n",
    "            if avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                self.save_checkpoint(save_path, epoch, optimizer, best_loss)\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= patience:\n",
    "                    print(f\"\ud83d\uded1 Early Stopping triggered after {patience} epochs without improvement.\")\n",
    "                    break\n",
    "                    \n",
    "        return history\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.eval()\n",
    "        tensor_X = torch.from_numpy(X.astype(np.float32)).to(self.device)\n",
    "        dataset = TensorDataset(tensor_X)\n",
    "        loader = DataLoader(dataset, batch_size=256, shuffle=False)\n",
    "        \n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch_x = batch[0]\n",
    "                out, _ = self(batch_x)\n",
    "                predictions.append(out.cpu().numpy())\n",
    "                \n",
    "        return np.concatenate(predictions, axis=0)\n",
    "    \n",
    "    def get_reconstruction_error(self, X):\n",
    "        \"\"\"\n",
    "        Calculates MSE for each sample window.\n",
    "        Returns: Array of shape (n_samples,) containing the MSE score.\n",
    "        \"\"\"\n",
    "        X_pred = self.predict(X)\n",
    "        mse = np.mean(np.square(X - X_pred), axis=(1, 2))\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Gold Data\n",
    "Look for data in Kaggle input directories or current directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "# Search for parquet files or use S3\n",
    "def load_parquet_data(filename, data_dir, is_local=False):\n",
    "    # Use localized configuration if available\n",
    "    storage_options = None\n",
    "    if is_local:\n",
    "        storage_options = config.get_pandas_storage_options()\n",
    "        \n",
    "    path = f\"{data_dir}/{filename}\"\n",
    "    if not path.startswith(\"s3://\") and not os.path.exists(path):\n",
    "         # Checking alternate local paths if not S3\n",
    "         possible_paths = [\n",
    "            filename,\n",
    "            f\"../input/{filename}\",\n",
    "            f\"../input/anomalydetection4pharma-gold-tensor/{filename}\",\n",
    "            f\"../gold/{filename}\"\n",
    "        ]\n",
    "         for p in possible_paths:\n",
    "            if os.path.exists(p):\n",
    "                path = p\n",
    "                break\n",
    "    \n",
    "    print(f\"Loading {filename} from {path}...\")\n",
    "    return pd.read_parquet(path, storage_options=storage_options)\n",
    "\n",
    "try:\n",
    "    df_train = load_parquet_data(\"train.parquet\", DATA_DIR, IS_LOCAL_ENV).sort_values('timestamp')\n",
    "    df_val = load_parquet_data(\"val.parquet\", DATA_DIR, IS_LOCAL_ENV).sort_values('timestamp')\n",
    "    \n",
    "    print(f\"Train Loaded: {len(df_train)} rows\")\n",
    "    print(f\"Val Loaded:   {len(df_val)} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Windows & Train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "history = model.train_model(\n",
    "    X_train, \n",
    "    X_val, \n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    lr=LR,\n",
    "    noise_factor=0.05,\n",
    "    save_path=os.path.join(RESULTS_DIR, \"lstm_ae_champion.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "metadata": {},
   "source": [
    "# 1. Guardar el Historial de Entrenamiento (CSV)\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(os.path.join(RESULTS_DIR, \"training_history.csv\"), index=False)\n",
    "print(f\"\u2705 Historial guardado: {RESULTS_DIR}/training_history.csv\")\n",
    "\n",
    "# 2. Guardar Metadata del Modelo (Configuraci\u00f3n)\n",
    "# Para poder cargarlo luego sin recordar los par\u00e1metros exactos\n",
    "model_config = {\n",
    "    \"window_size\": WINDOW_SIZE,\n",
    "    \"n_features\": len(TENSOR_FEATURES),\n",
    "    \"hidden_dim\": HIDDEN_DIM,\n",
    "    \"latent_dim\": LATENT_DIM,\n",
    "    \"features\": TENSOR_FEATURES\n",
    "}\n",
    "with open(os.path.join(RESULTS_DIR, \"model_config.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(model_config, f)\n",
    "print(f\"\u2705 Configuraci\u00f3n guardada: {RESULTS_DIR}/model_config.pkl\")\n",
    "\n",
    "# 3. Guardar Gr\u00e1fico de Loss (Imagen)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history['train_loss'], label='Train MAE', color='blue')\n",
    "plt.plot(history['val_loss'], label='Val MAE', color='orange')\n",
    "plt.title(\"Curva de Aprendizaje - LSTM Autoencoder\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MAE)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(os.path.join(RESULTS_DIR, \"loss_curve.png\"))\n",
    "print(f\"\u2705 Gr\u00e1fico guardado: {RESULTS_DIR}/loss_curve.png\")\n",
    "\n",
    "print(\"\\n\ud83d\udce6 ARCHIVOS LISTOS:\")\n",
    "print(\"1. lstm_ae_champion.pth\")\n",
    "print(\"2. model_config.pkl\")\n",
    "print(\"3. loss_curve.png\")\n",
    "print(\"4. training_history.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}